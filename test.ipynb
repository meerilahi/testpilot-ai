{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909c0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from typing import Dict, List\n",
    "from app.schemas.mark_bisep_subjective_sheet import MarkSubjectiveSheetRequest, MarkSubjectiveSheetResponse, QuestionResponse\n",
    "from app.database.mongodb import get_answer_sheet\n",
    "from app.core.extract_pages import extract_pages_from_pdf\n",
    "from app.core.ocr_answer_sheet import ocr_answer_sheet\n",
    "from app.core.mark_answer_sheet import mark_answer_sheet\n",
    "from app.core.crop_answer_sheet import crop_pdf_pages\n",
    "from app.core.filter_attempted import filter_attempted_questions\n",
    "from temp_data.sample_request import sample_request as request\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0440aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mark_sheet_to_json(mark_sheet: Dict[str, Any], filename: str = \"temp_data/mark_sheet.json\") -> None:\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(mark_sheet, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Mark sheet saved to {filename}\")\n",
    "\n",
    "def save_mark_sheet_to_markdown(mark_sheet: Dict[str, Any], filename: str = \"temp_data/mark_sheet.md\") -> None:\n",
    "    lines = [\"# Mark Sheet\\n\"]\n",
    "    for question_number, result in mark_sheet.items():\n",
    "        lines.append(f\"## Question {question_number}\\n\")\n",
    "        lines.append(f\"**Total Marks Awarded:** {result['marks']}\\n\")\n",
    "        lines.append(\"### Rubric Evaluation:\\n\")\n",
    "        for i, (awarded, justification) in enumerate(result['rubrics'], 1):\n",
    "            lines.append(f\"- **Point {i}:** {awarded} marks — {justification}\")\n",
    "        lines.append(\"\\n### Feedback:\\n\")\n",
    "        lines.append(f\"{result['feedback']}\\n\")\n",
    "        lines.append(\"---\\n\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    print(f\"Mark sheet saved as Markdown to {filename}\")\n",
    "\n",
    "def convert_mark_sheet_to_response(mark_sheet: Dict[str, Any]) -> MarkSubjectiveSheetResponse:\n",
    "    questions: List[QuestionResponse] = []\n",
    "    for qn_str, data in mark_sheet.items():\n",
    "        question_number = int(qn_str)\n",
    "        question_response = QuestionResponse(\n",
    "            question_number=question_number,\n",
    "            rubrics_marks=data[\"rubrics\"],\n",
    "            feedback=data[\"feedback\"],\n",
    "            presentation_score=data.get(\"presentation_score\", 0),\n",
    "            grammer_score=data.get(\"grammer_score\", 0.0),\n",
    "            total_marks=data[\"marks\"]\n",
    "        )\n",
    "        questions.append(question_response)\n",
    "    total_paper_marks = sum(q.total_marks for q in questions)\n",
    "    return MarkSubjectiveSheetResponse(\n",
    "        list_of_questions=questions,\n",
    "        total_paper_marks=total_paper_marks\n",
    "    )\n",
    "\n",
    "def write_ocr_to_markdown(ocr_result: dict, output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for question_number, content in ocr_result.items():\n",
    "        question_dir = os.path.join(output_dir, f\"question_{question_number}\")\n",
    "        os.makedirs(question_dir, exist_ok=True)\n",
    "        markdown_lines = content.get(\"markdown\", [])\n",
    "        markdown_content = \"\\n\\n\".join(markdown_lines)\n",
    "        img_data = content.get('image')\n",
    "        if img_data:\n",
    "            image_path = os.path.join(question_dir, 'diagram.png')\n",
    "            with open(image_path, \"wb\") as img_file:\n",
    "                img_file.write(base64.b64decode(img_data))\n",
    "            markdown_content += f\"\\n\\n![Image](diagram.png)\"\n",
    "        markdown_file_path = os.path.join(question_dir, f\"question_{question_number}.md\")\n",
    "        with open(markdown_file_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "            md_file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e543d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1. Answer Sheet with id biology2 Retrived from database\n"
     ]
    }
   ],
   "source": [
    "sheet_stream = get_answer_sheet(request.answer_sheet_id)\n",
    "print(f\"✅ 1. Answer Sheet with id {request.answer_sheet_id} Retrived from database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acc2a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 2. Answer Sheet cropped\n"
     ]
    }
   ],
   "source": [
    "cropped_sheet_stream = crop_pdf_pages(sheet_stream,page_indices=list(range(3,30)),left=65,right=65,top=130,bottom=130)\n",
    "print(\"✅ 2. Answer Sheet cropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4adf06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 3. Pages Extracted from pdf\n"
     ]
    }
   ],
   "source": [
    "images_dict = extract_pages_from_pdf(cropped_sheet_stream, request)\n",
    "print(\"✅ 3. Pages Extracted from pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3856b5cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ocr_result \u001b[38;5;241m=\u001b[39m \u001b[43mocr_answer_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m write_ocr_to_markdown(ocr_result,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_data/ocr_output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ 4. OCR Performed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Repositories/testpilot-ai/app/core/ocr_answer_sheet.py:26\u001b[0m, in \u001b[0;36mocr_answer_sheet\u001b[0;34m(images_dict)\u001b[0m\n\u001b[1;32m     24\u001b[0m         images \u001b[38;5;241m=\u001b[39m images \u001b[38;5;241m+\u001b[39m [image_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_base64\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;28;01mfor\u001b[39;00m image_obj \u001b[38;5;129;01min\u001b[39;00m response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     25\u001b[0m     result[qn][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(markdowns)\n\u001b[0;32m---> 26\u001b[0m     result[qn][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_base64_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Repositories/testpilot-ai/app/core/merge_images.py:9\u001b[0m, in \u001b[0;36mcombine_base64_images\u001b[0;34m(image_b64_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m images \u001b[38;5;241m=\u001b[39m [Image\u001b[38;5;241m.\u001b[39mopen(BytesIO(base64\u001b[38;5;241m.\u001b[39mb64decode(img_str))) \u001b[38;5;28;01mfor\u001b[39;00m img_str \u001b[38;5;129;01min\u001b[39;00m image_b64_list]\n\u001b[1;32m      8\u001b[0m total_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(img\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images)\n\u001b[0;32m----> 9\u001b[0m max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m combined_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, (max_width, total_height), color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m))\n\u001b[1;32m     11\u001b[0m y_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "ocr_result = ocr_answer_sheet(images_dict)\n",
    "write_ocr_to_markdown(ocr_result,\"temp_data/ocr_output\")\n",
    "print(\"✅ 4. OCR Performed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aafe7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 5. Attempted Questions Filtered\n"
     ]
    }
   ],
   "source": [
    "filter_qns = filter_attempted_questions(ocr_result)\n",
    "print(\"✅ 5. Attempted Questions Filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38abecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 6. All Answer Sheet Marked\n"
     ]
    }
   ],
   "source": [
    "mark_sheet = mark_answer_sheet(ocr_result, request, filter_qns)\n",
    "print(\"✅ 6. All Answer Sheet Marked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c91b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mark_sheet_to_json(mark_sheet, \"temp_data/evaluated_sheet.json\")\n",
    "save_mark_sheet_to_markdown(mark_sheet, \"temp_data/evaluated_sheet.md\")\n",
    "response_model = convert_mark_sheet_to_response(mark_sheet)\n",
    "print(\"✅ 7. Response Object generated from Marked Sheet\")\n",
    "print(response_model.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
